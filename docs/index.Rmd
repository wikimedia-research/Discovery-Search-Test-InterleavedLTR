---
params:
  env: dev # alt: prod
title: "[WIP] First assessment of learning-to-rank"
subtitle: "Testing machine-learned ranking of search results on English Wikipedia"
date: "`r format(Sys.Date(), '%d %B %Y')`"
author:
- affiliation: "Senior Software Engineer, Wikimedia Foundation"
  name: "Erik Bernhardson"
- affiliation: "Software Engineer, Wikimedia Foundation"
  name: "David Causse"
- affiliation: "Senior Software Engineer, Wikimedia Foundation"
  name: "Trey Jones"
- affiliation: "Data Analyst, Wikimedia Foundation"
  name: "Mikhail Popov"
- affiliation: "Product Manager, Wikimedia Foundation"
  name: "Deb Tankersley"
abstract: >
  English Wikipedia searchers who received results from machine learned-ranking (MLR) were significantly more likely to engage with those results -- 36% (rescore window of 20) and 37% (rescore window of 1024) clickthrough rates -- than the control group (31%) who received results ranked by BM25. Users with MLR results were also more likely to click on the first search result first. When we compared how long users stayed on those visited pages, the results were inconclusive. Users who saw MLR results with the rescore window of 1024 were more likely to view additional pages of search results, but not significantly. When the users were presented with an interleaved mix of results, they exhibited some preference for MLR results over the default BM25 results. Specifically, users appeared to have a preference for the MLR results with a rescore window of 1024 more than a rescore window of 20, and they stayed on those visited results longer.
output:
  html_document:
    includes:
      after_body: suffix.html
    code_folding: hide
    css: style.css
    fig_caption: yes
    fig_width: 10
    fig_height: 6
    highlight: zenburn
    keep_md: no
    mathjax: https://tools-static.wmflabs.org/cdnjs/ajax/libs/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML
    md_extensions: +raw_html +markdown_in_html_blocks +tex_math_dollars +fancy_lists +startnum +lists_without_preceding_blankline +footnotes +implicit_header_references
    self_contained: yes # change this to no for the final draft
    theme: flatly
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: no
  pdf_document:
    citation_package: natbib
    fig_height: 6
    fig_width: 10
    keep_tex: no
    latex_engine: xelatex
    template: svm-latex-ms.tex
bibliography: bibliography.bib
csl: machine-learning.csl
link-citations: yes
nocite: |
  @R-rmarkdown, @R-magrittr, @R-tidyr, @R-dplyr, @R-ggplot2, @R-wmf, @R-dt, @R-jsonlite
fontsize: 11pt
geometry: margin=1in
header-includes:
  - \usepackage{floatrow}
  - \floatsetup[table]{capposition=bottom}
---
```{css, echo=FALSE}
@import url('https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro|Source+Serif+Pro');
body, p {
  font-family: 'Source Serif Pro', serif;
  font-size: 12pt;
}
pre, code {
  font-family: 'Source Code Pro', monospace;
}
table, tr, td, h1, h2, h3, h4, h5, h6 {
  font-family: 'Source Sans Pro', sans-serif;
}
p.abstract {
  font-family: 'Source Sans Pro', sans-serif;
  font-weight: bold;
  font-size: 14pt !important;
}
```
```{js, echo=FALSE}
$(function() {
  /* Lets the user click on the images to view them in full resolution. */
  $("div.figure img").wrap(function() {
    var link = $('<a/>');
    link.attr('href', $(this).attr('src'));
    link.attr('title', $(this).attr('alt'));
    link.attr('target', '_blank');
    return link;
  });
  $("p.abstract").text("Executive Summary");
  $("div#wmf").wrap('<a href="https://wikimediafoundation.org/" />');
});
```
```{r setup, include=FALSE}
set.seed(0); options(digits = 3, scipen = 500)
library(magrittr)
library(knitr)
library(kableExtra)
if (!"printr" %in% installed.packages()[, "Package"]) {
  install.packages("printr", type = "source", repos = c("Yihui Xie" = "http://yihui.name/xran", CRAN = "http://cran.rstudio.com"))
} else {
  loadNamespace("printr")
}
is_html <- function() {
  if (length(opts_knit$get("rmarkdown.pandoc.to")) > 0) {
    return(opts_knit$get("rmarkdown.pandoc.to") == "html")
  } else {
    return(FALSE)
  }
}
if (is_html()) {
  options(knitr.table.format = "html")
} else {
  options(knitr.table.format = "latex")
}
opts_chunk$set(
  echo = is_html(), warning = FALSE, message = FALSE,
  out.width = '\\textwidth', dev = 'png', fig.ext = 'png',
  dpi = ifelse(is_html(), 150, 300)
)
path <- function(x) {
  if (grepl("docs", getwd(), fixed = TRUE)) {
    return(file.path("..", x))
  } else {
    return(x)
  }
}
fable <- function(x, caption = NULL, ...) {
  if (is_html()) {
    return({
      kable(x, caption = caption, booktabs = TRUE) %>%
      kable_styling(bootstrap_options = c("striped", "hover"), ...)
    })
  } else {
    return(kable(x, caption = caption, ...))
  }
}
interpret_bf <- function(bf, interpreter = c('Kass and Raftery', 'Harold Jeffreys')) {
  if (interpreter[1] == 'Kass and Raftery') {
    bf_transformed <- 2 * log(bf)
    if ( bf_transformed <= 2 ) {
      return("not worth more than a bare mention")
    } else if ( bf_transformed > 2 && bf_transformed <= 6 ) {
      return("positive evidence against null hypothesis of independence")
    } else if ( bf_transformed > 6 && bf_transformed <= 10 ) {
      return("strong evidence against null hypothesis of independence")
    } else { # bf_transformed > 10
      return("very strong evidence against null hypothesis of independence")
    }
  } else { # interpreter == 'Harold Jeffreys'
    bf_transformed <- log10(bf)
    if ( bf_transformed <= 1/2 ) {
      return("not worth more than a bare mention")
    } else if ( bf_transformed > 1/2 && bf_transformed <= 1 ) {
      return("substantial evidence againstnull hypothesis of independence")
    } else if ( bf_transformed > 1 && bf_transformed <= 2 ) {
      return("strong evidence against null hypothesis of independence")
    } else { # bf_transformed > 2
      return("decisive evidence against null hypothesis of independence")
    }
  }
}
```
```{r captions, include=FALSE}
# Manual figure & table captioning:
library(captioner) # install.packages("captioner")
table_caps <- captioner(prefix = "Table")
figure_caps <- captioner(prefix = "Figure")
code_caps <- captioner(prefix = "Snippet")
# Custom caption formatting and printing:
format_caption <- function(caps, name) {
  return({
    sub(caps(name, display = "cite"),
      paste0(ifelse(is_html(), "**", "\\textbf{"), caps(name, display = "cite"), ifelse(is_html(), "**", "}")),
      caps(name, display = "full"), fixed = TRUE) %>%
    sub("  ", " ", ., fixed = TRUE)
  })
}
print_caption <- function(formatted_caption) {
  cat(paste0('<p class = "caption">', formatted_caption, '</p>', collapse = ''))
}
# TODO: captions
```
```{r links, echo=FALSE, results='asis'}
if (is_html()) {
  cat('<p style="text-align: center;"><a title="By Github project phacility/phabricator & w:de:User:Perhelion [Apache License 2.0 (http://www.apache.org/licenses/LICENSE-2.0)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File%3AFavicon-Phabricator-WM.png"><img width="16" alt="Favicon-Phabricator-WM" src="https://upload.wikimedia.org/wikipedia/commons/7/72/Favicon-Phabricator-WM.png"/></a> <a href="https://phabricator.wikimedia.org/T171215", title="T171215">Phabricator ticket</a> | <a title="By The Open Source Initiative [CC BY 2.5 (http://creativecommons.org/licenses/by/2.5)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File%3AOpen_Source_Initiative_keyhole.svg"><img width="16" alt="Open Source Initiative keyhole" src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Open_Source_Initiative_keyhole.svg/16px-Open_Source_Initiative_keyhole.svg.png"/></a> <a href="https://github.com/wikimedia-research/Discovery-Search-Test-InterleavedLTR">Open source analysis</a></p>')
} else {
  cat('\\let\\thefootnote\\relax\\footnote{Source code is available on GitHub (\\href{https://github.com/wikimedia-research/Discovery-Search-Test-InterleavedLTR}{wikimedia-research/Discovery-Search-Test-InterleavedLTR})}')
}
```

# Introduction

## Learning to rank

Previously, our search engine used term frequency—inverse document frequency ([tf—idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)) for ranking documents (e.g. articles and other pages on English Wikipedia). After successful A/B testing [@BM25-1; @BM25-2], we switched to [BM25 scoring algorithm](https://en.wikipedia.org/wiki/Okapi_BM25) which is currently in production on almost all languages, except a few space-less languages. Our current efforts are focused on information retrieval using [machine-learned ranking](https://en.wikipedia.org/wiki/Learning_to_rank) (MLR). In MLR, a model is trained to predict a document's relevance from various document-level and [query-level](https://en.wikipedia.org/wiki/Query_level_feature) features which represent the document.

*MjoLniR* -- our Python and Spark-based library for handling the backend data processing for Machine Learned Ranking at Wikimedia -- uses a [Deep Belief Network](https://en.wikipedia.org/wiki/Deep_belief_network) via [XGBoost](https://en.wikipedia.org/wiki/Xgboost) and is [available as open source](https://github.com/wikimedia/search-MjoLniR).

## Interleaved search results

The way we have been assessing changes to search has so far relied on A/B testing -- randomized experiments -- wherein the control group receives results using the latest configuration and the test group (or groups) receives results using the experimental configuration. Another way to evaluate the user-perceived relevance of search results from the experimental configuration relies on a technique called *interleaving*. In it, each user is their own baseline -- we perform two searches behind the scenes and then interleave them together into a single set of results using the team draft algorithm described by Chapelle et al. [-@Interleaved:2012]. By keeping track of which results belong to which ranking function when the user clicks on them, we can estimate a preference for one ranker over the other.

## Experimental groups

In total there were 6 groups that users could be randomly assigned to. Three of the groups were using in a traditional A/B test setting -- some users were randomly assigned to a control group while others were assigned to one of the two experimental groups.

- The control group had results ranked by BM25.

- The "MLR (20)" experimental group had results ranked by machine learning with a rescore window of 20. This means the model was trained against labeled data for the first 20 results that were displayed to users.

- The "MLR (1024)" experimental group had results ranked by machine learning with a rescore window of 1024. This means the model was trained against labeled data for the first 1024 results that were displayed to users.

The remaining three groups were tested via interleaving the results. Two of the groups saw results that were a mix of BM25-ranked results and machine learning-ranked results, and one group saw results that were a mix of results from machine learned-rankers but with different rescoring windows.

# Methods

This test's event logging (EL) was implemented in JavaScript according to the [TestSearchSatisfaction2 (TSS2)](https://meta.wikimedia.org/wiki/Schema:TestSearchSatisfaction2) schema, which is the one used by the Search team for its metrics on desktop, data was stored in a MySQL database, and analyzed and reported using R [@R-base].

```{r pkgs, echo=FALSE}
import::from(dplyr, group_by, ungroup, keep_where = filter, mutate, arrange, select, transmute, left_join, summarize, bind_rows, case_when, if_else, rename)
library(ggplot2)
```

# Results

```{r data, echo=FALSE}
date_range <- "20170808-20170829"
results <- readr::read_rds(glue::glue("../data/full-events_{date_range}.rds"))
results$group_id %<>% factor(
  c("control", "ltr-20", "ltr-1024"),
  c("BM25 (Control)", "MLR @ 20", "MLR @ 1024")
)
```

## Traditional test

```{r data_ab, echo=FALSE}
page_visits <- readr::read_rds(glue::glue("../data/page-visits_{date_range}.rds"))
page_visits$group_id %<>% factor(
  c("control", "ltr-20", "ltr-1024"),
  c("BM25 (Control)", "MLR @ 20", "MLR @ 1024")
)
serp_clicks <- readr::read_rds(glue::glue("../data/serp-clicks_{date_range}.rds"))
serp_clicks$group_id %<>% factor(
  c("control", "ltr-20", "ltr-1024"),
  c("BM25 (Control)", "MLR @ 20", "MLR @ 1024")
)
```

### Zero results rate

```{r zrr}
zrr <- serp_clicks %>%
  group_by(group_id, session_id, search_id) %>%
  summarize(max_hits = max(hits_returned, na.rm = TRUE)) %>%
  mutate(some_results = max_hits > 0) %>%
  group_by(group_id) %>%
  summarize(searches = n(), zero = sum(!some_results)) %>%
  { cbind(group = .$group_id, binom::binom.bayes(.$zero, .$searches)) }

ggplot(zrr, aes(x = group, color = group, y = mean, ymin = lower, ymax = upper)) +
  geom_linerange() +
  geom_label(aes(label = sprintf("%.2f%%", 100 * mean)), show.legend = FALSE) +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous(
    labels = scales::percent_format(), limits = c(0.08, 0.1),
    breaks = seq(0.08, 0.1, 0.01), minor_breaks = seq(0.08, 0.1, 0.005)
  ) +
  labs(
    x = "Group", color = "Group", y = "Zero results rate",
    title = "Proportion of searches yielding no results, by group",
    subtitle = sprintf("95%% credible intervals* computed using data from %s to %s", min(serp_clicks$date), max(serp_clicks$date)),
    caption = "* constructed using highest probability density (HPD)"
  ) +
  wmf::theme_min(base_family = "Source Sans Pro")
```

### Clickthrough rate

```{r ctr}
ctr <- serp_clicks %>%
  group_by(group_id, session_id, search_id) %>%
  summarize(
    clickthrough = any(event == "click"),
    max_hits = max(hits_returned, na.rm = TRUE)
  ) %>%
  ungroup %>%
  keep_where(max_hits > 0) %>% # TODO: filter out searches with 0 results
  group_by(group_id) %>%
  summarize(searches = n(), clickthroughs = sum(clickthrough)) %>%
  { cbind(group = .$group_id, binom::binom.bayes(.$clickthroughs, .$searches)) }

ggplot(ctr, aes(x = group, color = group, y = mean, ymin = lower, ymax = upper)) +
  geom_linerange() +
  geom_label(aes(label = sprintf("%.2f%%", 100 * mean)), show.legend = FALSE) +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    x = "Group", color = "Group", y = "Clickthrough rate",
    title = "Proportion of searches where the user clicked a result, by group",
    subtitle = sprintf("95%% credible intervals* computed using data from %s to %s", min(serp_clicks$date), max(serp_clicks$date)),
    caption = "* constructed using highest probability density (HPD)"
  ) +
  wmf::theme_min(base_family = "Source Sans Pro")
```

### Position of first click

```{r first_click}
first_click <- serp_clicks %>%
  keep_where(event == "click") %>%
  group_by(group_id, session_id, search_id) %>%
  dplyr::top_n(1, ts) %>%
  group_by(group_id, position) %>%
  dplyr::tally() %>%
  mutate(
    position = dplyr::if_else(
      position < 4,
      purrr::map_chr(position + 1, toOrdinal::toOrdinal),
      "5+"
    ),
    position = factor(position, c("1st", "2nd", "3rd", "4th", "5+"))
  ) %>%
  group_by(group_id, position) %>%
  summarize(n = sum(n)) %>%
  mutate(total = sum(n)) %>%
  ungroup %>%
  { cbind(., binom::binom.bayes(.$n, .$total)) }

ggplot(first_click, aes(x = position, y = mean, fill = group_id)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), color = "white") +
  geom_errorbar(aes(ymin = lower, ymax = upper), position = position_dodge(width = 0.9), width = 0.2) +
  scale_fill_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    x = "Position", y = "Proportion of searches with a clickthrough",
    fill = "Group", title = "Position of first clicked result, by group",
    subtitle = "Error bars indicate 95% credible interval (via HPD)"
  ) +
  wmf::theme_min(base_family = "Source Sans Pro")
```

### Page visit times

```{r surv_ab, cache=TRUE}
library(survminer)
library(survival)
checkins <- c(0, 10, 20, 30, 40, 50, 60, 90, 120, 150, 180, 210, 240, 300, 360, 420)
temp <- page_visits[, {
  if (any(.SD$event == "checkin")) {
    last_checkin <- max(.SD$checkin, na.rm = TRUE)
    idx <- which(checkins > last_checkin)
    if (length(idx) == 0) idx <- 16 # length(checkins) = 16
    next_checkin <- checkins[min(idx)]
    status <- ifelse(last_checkin == 420, 0, 3)
    data.table::data.table(
      `last check-in` = as.integer(last_checkin),
      `next check-in` = as.integer(next_checkin),
      status = as.integer(status)
    )
  }
}, by = c("group_id", "session_id", "search_id")]
surv <- survival::Surv(
  time = temp$`last check-in`,
  time2 = temp$`next check-in`,
  event = temp$status,
  type = "interval"
)
fit <- survival::survfit(surv ~ temp$group_id)
km <- survminer::ggsurvplot(
  fit, data = temp,
  palette = "Set1", conf.int = FALSE,
  ggtheme = wmf::theme_min(base_family = "Source Sans Pro"),
  title = "How long users stay on clicked results, by group",
  subtitle = "Kaplan–Meier curve of estimated survival probability",
  xlab = "Time (s)", ylab = "Probability of visited page staying open this long"
)
km$plot <- km$plot + scale_y_continuous(labels = scales::percent_format())
print(km)
```

### Pagination navigation

```{r explored}
explored <- serp_clicks %>%
  keep_where(event == "searchResultPage" & hits_returned > 0) %>%
  group_by(group_id, session_id, search_id) %>%
  summarize(explored = max(offset, na.rm = TRUE) > 0) %>%
  group_by(group_id) %>%
  summarize(searches = n(), explored = sum(explored)) %>%
  { cbind(group = .$group_id, binom::binom.bayes(.$explored, .$searches)) }

ggplot(explored, aes(x = group, color = group, y = mean, ymin = lower, ymax = upper)) +
  geom_linerange() +
  geom_label(aes(label = sprintf("%.2f%%", 100 * mean)), show.legend = FALSE) +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    x = "Group", color = "Group", y = "Proportion of non-empty searches",
    title = "Proportion of searches where the user viewed additional results, by group",
    subtitle = sprintf("95%% HPD intervals computed using data from %s to %s", min(serp_clicks$date), max(serp_clicks$date)),
    caption = "By tracking the offset values, we are able to know when the user clicked on page 2 or 3 of search results."
  ) +
  wmf::theme_min(base_family = "Source Sans Pro")
```

## Interleaved test

```{r data_il, echo=FALSE}
interleaved <- readr::read_rds(glue::glue("../data/interleaved_{date_range}.rds"))
interleaved$group_id %<>% factor(
  c("ltr-i-20", "ltr-i-1024", "ltr-i-20-1024"),
  c("[A] BM25 vs [B] MLR (20)", "[A] BM25 vs [B] MLR (1024)", "[A] MLR (20) vs [B] MLR (1024)")
)
```

### Preference

```{r pref, cache=TRUE}
events <- interleaved[
  !is.na(team) & team != "" & event == "visitPage",
  c("date", "group_id", "session_id", "search_id", "team"),
  with = TRUE
]
events <- events[order(events$date, events$group_id, events$session_id, events$search_id, events$team), ]
pref_daily <- events[, j = list(
  "Sampling sessions" = wmf::interleaved_preference(paste(.SD$session_id), .SD$team),
  "Sampling searches" = wmf::interleaved_preference(paste(.SD$session_id, .SD$search_id), .SD$team)
), by = c("date", "group_id")] %>%
  tidyr::gather(method, observed, -c(date, group_id))
pref_overall <- events[, j = list(
  "Sampling sessions" = wmf::interleaved_preference(paste(.SD$session_id), .SD$team),
  "Sampling searches" = wmf::interleaved_preference(paste(.SD$session_id, .SD$search_id), .SD$team)
), by = c("group_id")] %>%
  tidyr::gather(method, observed, -c(group_id))
```

```{r bootstrap_sampling, cache=TRUE}
data.table::setDTthreads(4) # not sure if this actually even helps
m <- ifelse(params$env == "dev", 100, 10000)
prefs_by_session <- events[, {
  preferences <- vapply(1:m, function(i) {
    set.seed(i)
    n <- data.table::uniqueN(.SD$session_id)
    resampled <- split(.SD, .SD$session_id)[sample.int(n, n, replace = TRUE)]
    names(resampled) <- 1:n
    resampled %>%
      dplyr::bind_rows(.id = "sample") %>%
      group_by(session_id) %>%
      mutate(sample_id = paste(session_id, as.numeric(factor(sample)), sep = "-")) %>%
      ungroup %>%
      { wmf::interleaved_preference(.$sample_id, .$team) }
  }, 0.0)
  data.frame(sample = 1:m, preference = preferences, method = "Sampling sessions", stringsAsFactors = FALSE)
}, by = c("date", "group_id")]
prefs_by_search <- events[, {
  preferences <- vapply(1:m, function(i) {
    set.seed(i)
    n <- data.table::uniqueN(.SD[, c("session_id", "search_id"), with = TRUE])
    resampled <- split(.SD, paste0(.SD$session_id, .SD$search_id))[sample.int(n, n, replace = TRUE)]
    names(resampled) <- 1:n
    resampled %>%
      dplyr::bind_rows(.id = "sample") %>%
      group_by(session_id, search_id) %>%
      mutate(sample_id = paste(session_id, search_id, as.numeric(factor(sample)), sep = "-")) %>%
      ungroup %>%
      { wmf::interleaved_preference(.$sample_id, .$team) }
  }, 0.0)
  data.frame(sample = 1:m, preference = preferences, method = "Sampling searches", stringsAsFactors = FALSE)
}, by = c("date", "group_id")]
prefs <- rbind(prefs_by_session, prefs_by_search)
daily <- prefs %>%
  group_by(date, group_id, method) %>%
  summarize(
    lower = quantile(preference, 0.025, na.rm = TRUE),
    upper = quantile(preference, 0.975, na.rm = TRUE)
  ) %>%
  ungroup %>%
  left_join(pref_daily, by = c("date", "group_id", "method")) %>%
  mutate(preferred = dplyr::if_else(observed > 0, "A", "B")) %>%
  group_by(group_id, method, preferred) %>%
  arrange(date) %>%
  mutate(counter = cumsum(!is.na(date))) %>%
  ungroup
overall <- prefs %>%
  group_by(group_id, method, date) %>%
  summarize(
    lower95 = quantile(preference, 0.025, na.rm = TRUE),
    lower80 = quantile(preference, 0.1, na.rm = TRUE),
    upper95 = quantile(preference, 0.975, na.rm = TRUE),
    upper80 = quantile(preference, 0.9, na.rm = TRUE),
  ) %>%
  summarize(
    lower95 = median(lower95, na.rm = TRUE),
    upper95 = median(upper95, na.rm = TRUE),
    lower80 = median(lower80, na.rm = TRUE),
    upper80 = median(upper80, na.rm = TRUE)
  ) %>%
  ungroup %>%
  left_join(pref_overall, by = c("group_id", "method"))
```

```{r bootstrap_viz_daily, fig.width = 16, fig.height = 8}
ggplot(keep_where(daily, !is.na(observed)), aes(x = date, y = observed)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.25) +
  geom_line() +
  geom_segment(
    aes(xend = date, yend = ifelse(preferred == "A", 0.275, -0.275), color = preferred),
    linetype = "dotted"
  ) +
  geom_point(aes(color = preferred)) +
  geom_text(
    aes(y = ifelse(preferred == "A", 0.3, -0.3), label = counter, color = preferred),
    show.legend = FALSE, fontface = "bold"
  ) +
  scale_color_brewer(palette = "Set1") +
  facet_grid(method ~ group_id) +
  labs(
    x = "Date", y = "B ← Preference → A",
    title = "Preference for results from two rankers, daily by group",
    subtitle = "Showing counts of how many times users preferred one ranking over the other",
    caption = "95% confidence intervals were bootstrapped using two different sampling approaches"
  ) +
  wmf::theme_facet(base_family = "Source Sans Pro")
```
```{r bootstrap_viz_overall}
ggplot(
  mutate(overall, method = sub("\\s", "\n", method)),
  aes(x = method, y = observed)
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_linerange(aes(ymin = lower95, ymax = upper95), size = 0.5) +
  geom_linerange(aes(ymin = lower80, ymax = upper80), size = 1.5) +
  geom_label(aes(label = sprintf("%.4f", observed))) +
  facet_wrap(~ group_id) +
  labs(
    x = "Bootstrap approach", y = "B ← Preference → A",
    title = "Preference for results from two rankers, by group",
    caption = "80% (thick) and 95% (thin) confidence intervals were bootstrapped using two different sampling approaches"
  ) +
  wmf::theme_facet()
```

### Page visit times

```{r surv_il, cache=TRUE}
temp <- interleaved[!is.na(team) & team != "", {
  if (any(.SD$event == "checkin")) {
    last_checkin <- max(.SD$checkin, na.rm = TRUE)
    idx <- which(checkins > last_checkin)
    if (length(idx) == 0) idx <- 16 # length(checkins) = 16
    next_checkin <- checkins[min(idx)]
    status <- ifelse(last_checkin == 420, 0, 3)
    data.table::data.table(
      `last check-in` = as.integer(last_checkin),
      `next check-in` = as.integer(next_checkin),
      status = as.integer(status),
      team = .SD$team[1]
    )
  }
}, by = c("group" = "group_id", "session_id", "search_id")] %>%
  as.data.frame
temp$group %<>% factor(
  c("[A] BM25 vs [B] MLR (20)", "[A] BM25 vs [B] MLR (1024)", "[A] MLR (20) vs [B] MLR (1024)"),
  c("[Group 1] BM25 vs LTR (20)", "[Group 2] BM25 vs LTR (1024)", "[Group 3] LTR (20) vs LTR (1024)")
)
surv <- survival::Surv(
  time = temp$`last check-in`,
  time2 = temp$`next check-in`,
  event = temp$status,
  type = "interval"
)
fit <- survival::survfit(surv ~ temp$group + temp$team)
km <- survminer::ggsurvplot(
  fit, data = temp, palette = "Dark2",
  title = "How long users stay on each team's results",
  subtitle = "Kaplan–Meier curve of estimated survival probability",
  xlab = "Time (s)", ylab = "Probability of visited page staying open this long"
)
km$plot <- km$plot +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_continuous(labels = function(x) {
    mins <- floor(x / 60); secs <- x %% 60
    labs <- sprintf("%.0fm %.0fs", mins, secs)
    labs[mins == 0] <- sprintf("%.0fs", secs[mins == 0])
    labs[secs == 0] <- sprintf("%.0fm", mins[secs == 0])
    return(labs)
  }, breaks = c(0, 0.5, 1:7) * 60) +
  facet_wrap(~ group) +
  wmf::theme_facet()
print(km)
```

```{r bibliograpby, results='asis', echo=FALSE}
if (is_html()) {
  cat("# References\n")
} else {
  cat("\\nocite{*}\n")
}
```
